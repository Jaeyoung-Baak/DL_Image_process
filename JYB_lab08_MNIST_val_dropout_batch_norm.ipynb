{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab08-MNIST-val-dropout-batch-norm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIRxHin2Y1Z1"
      },
      "source": [
        "## Lab 8 – Dealing with Overfitting\n",
        "- MNIST dataset\n",
        "  - Handwritten digits images\n",
        "  - 28 x 28 greyscale\n",
        "- Source: https://www.cs.toronto.edu/~lczhang/360/lec/w05/overfit.html\n",
        "\n",
        "### Load the data into training and validation sets\n",
        "- for purposes of overfitting, training data will be largely reduced\n",
        "- no normalisation is applied yet\n",
        "- `batch_size` is set to 20\n",
        "- we will also **NOT** use GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75guQ2SXmdGX"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size = 20\n",
        "\n",
        "# for reproducibility\n",
        "torch.manual_seed(1)\n",
        "\n",
        "train_data = datasets.MNIST('./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "train_data = list(train_data)\n",
        "train_set = train_data[:20]     # 20 images\n",
        "val_set   = train_data[200:2200]# 2000 images\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set,\n",
        "                                               batch_size=batch_size,\n",
        "                                               shuffle=True) # shuffle after every epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtBy6CxizTZD"
      },
      "source": [
        "### View a few images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0NzwHpezCzl"
      },
      "source": [
        "batch = next(iter(train_loader))\n",
        "\n",
        "images, labels = batch\n",
        "\n",
        "print(images.shape)\n",
        "print(labels)\n",
        "\n",
        "# Create a grid \n",
        "plt.figure(figsize=(12,12))\n",
        "grid = torchvision.utils.make_grid(tensor=images, nrow=4) # nrow = number of images displayed in each row\n",
        "\n",
        "print(f\"class labels: {labels}\")\n",
        "\n",
        "# Use grid.permute() to transpose the grid so that the axes meet the specifications required by \n",
        "# plt.imshow(), which are [height, width, channels]. PyTorch dimensions are [channels, height, width].\n",
        "plt.imshow(grid.permute(1,2,0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptnSbZTI8WSQ"
      },
      "source": [
        "### Create a NN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7bbSSDQmoqa"
      },
      "source": [
        "class MNIST_DNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(28 * 28, 50)\n",
        "        self.layer2 = nn.Linear(50, 20)\n",
        "        self.layer3 = nn.Linear(20, 10)\n",
        "    def forward(self, img):\n",
        "        flattened = img.reshape(-1, 28 * 28)\n",
        "        out1 = F.relu(self.layer1(flattened))\n",
        "        out2 = F.relu(self.layer2(out1))\n",
        "        output = self.layer3(out2)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3skUHRs8pDj"
      },
      "source": [
        "### Function to Calculate Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iLuiAwnp7Tx"
      },
      "source": [
        "def get_accuracy(model, data):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval() # For later #\n",
        "    for imgs, labels in torch.utils.data.DataLoader(data, batch_size=64):\n",
        "        output = model(imgs)\n",
        "        pred = output.max(1, keepdim=True)[1] # get the index of the max logit\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "    return 100.0 * correct / total\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGR3svRUwmlD"
      },
      "source": [
        "## Function for Training Loop\n",
        "- We will run over 500 iterations in batches of 20\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_3Qh-6ZoQ8L"
      },
      "source": [
        "def train_model(model, train, valid, n_iters=500, learn_rate=0.01, weight_decay=0):\n",
        "  # Lists to store model's performance information\n",
        "  iters, losses, train_acc, val_acc = [], [], [], []\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(model.parameters(), lr=learn_rate, momentum=0.9, weight_decay=weight_decay)\n",
        "\n",
        "  for i in range(n_iters):\n",
        "    for images, labels in iter(train_loader):\n",
        "      model.train() # For Dropout and Batch Norm layers #\n",
        "      out = model(images)           # forward pass\n",
        "      loss = criterion(out, labels) # compute the total loss\n",
        "      loss.backward()               # backward pass (compute parameter updates)\n",
        "      optimizer.step()              # make the updates for each parameter\n",
        "      optimizer.zero_grad()         # reset the gradients for the next iteration\n",
        "\n",
        "      # Save the current training and validation information at every 10th iteration\n",
        "      if (i+1) % 10 == 0:\n",
        "          iters.append(i)\n",
        "          losses.append(float(loss)/batch_size)        # compute *average* loss\n",
        "          train_acc.append(get_accuracy(model, train)) # compute training accuracy \n",
        "          val_acc.append(get_accuracy(model, valid))   # compute validation accuracy\n",
        "\n",
        "\n",
        "  print(f'Plotting')\n",
        "  # Plotting Training Loss, Accuracy and Validation Accuracy\n",
        "  plt.figure(figsize=(10,4))\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.title(\"Training Curve\")\n",
        "  plt.plot(iters, losses, label=\"Train\")\n",
        "  plt.xlabel(\"Iterations\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.title(\"Training Curve\")\n",
        "  plt.plot(iters, train_acc, label=\"Train\")\n",
        "  plt.plot(iters, val_acc, label=\"Validation\")\n",
        "  plt.xlabel(\"Iterations\")\n",
        "  plt.ylabel(\"Training Accuracy\")\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()\n",
        "\n",
        "  print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
        "  print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3TegIv5CPP0"
      },
      "source": [
        "### Build A Basic Model\n",
        "- uses 20 images for training data, contained in `train_set`\n",
        "- uses 2000 images for validation data, contained in `val_set`\n",
        "- trains over 500 iterations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NLbJFKO_KNu"
      },
      "source": [
        "model = MNIST_DNN()\n",
        "train_model(model, train_set, val_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O90UjVfz0PwJ"
      },
      "source": [
        "# Based on the plotted graphs, answer the following questions:\n",
        "\n",
        "# Q1. What is the final loss of the training set and at which iteration was this achieved? \n",
        "\n",
        "# Q2. What is the final accuracy of the training set and at which iteration was this achieved? \n",
        "\n",
        "# Q3. What do these values tell you about the model's performance on the training data?\n",
        "\n",
        "# Q4. What is the model's final accuracy on the validation set?\n",
        "\n",
        "# Q5. Would more iterations help make a better model? Why or why not?\n",
        "\n",
        "# Q6. Would this model work well on classifying other handwritten digits? Why or why not?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1WlxkuJ6Gkc"
      },
      "source": [
        "### Add Normalisation and Weight Decay\n",
        "- Our basic model gets to around 52-55% accuracy on the validation set.\n",
        "- Normalisation will ensure the spread of the values are within a certain range. For example, normalising with mean value 0.5 and std 0.5 subtracts mean (0.5) from each pixel, and divides the result by std (0.5). So, each pixel intensity will be in the range `[-1, 1]`.\n",
        "- Weight decay penalises large weights. We avoid large weights because large weights mean that the prediction relies a lot on the content of one pixel, or on one unit. Intuitively, the classification of an image should NOT depend heavily on the content of one pixel, or even a few pixels.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUFX4__ibRab"
      },
      "source": [
        "transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "        ])\n",
        "\n",
        "# for reproducibility\n",
        "torch.manual_seed(1)\n",
        "\n",
        "train_data = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "train_data = list(train_data)\n",
        "train_set = train_data[:20]     # 20 images\n",
        "val_set   = train_data[200:2200]# 2000 images\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set,\n",
        "                                               batch_size=batch_size,\n",
        "                                               shuffle=True) # shuffle after every epoch\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNxS3rHFMbh7"
      },
      "source": [
        "### Train a model with Normalisation and Weight Decay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-za0SLTLAXO_"
      },
      "source": [
        "model = MNIST_DNN()\n",
        "train_model(model, train_set, val_set, weight_decay=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uvHDKOpEH4H"
      },
      "source": [
        "### Dropouts\n",
        "- Randomly \"zero out\", or \"remove\" a portion of neurons from each training iteration\n",
        "- In different iterations of training, we will drop out a different set of neurons\n",
        "- Prevents weights from being overly dependent on each other, e.g. one weight could be unnecessarily large to compensate for another unnecessarily large weight with the opposite sign. Weights are encouraged to be \"more independent\" of one another\n",
        "- During validation, we will not drop out any neurons. This means that our training time and test time behaviour of dropout layers are different. In the code for the functions `train_model()` and `get_accuracy()`, we use `model.train()` and `model.eval()` to flag whether we want the model's training behaviour, or test time behaviour."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oRsGqkvC1lD"
      },
      "source": [
        "class MNIST_Dropout(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(28 * 28, 50)\n",
        "        self.layer2 = nn.Linear(50, 20)\n",
        "        self.layer3 = nn.Linear(20, 10)\n",
        "        self.dropout = nn.Dropout(0.4) # drop out layer with 40% dropped out neuron\n",
        "    def forward(self, img):\n",
        "        flattened = img.view(-1, 28 * 28)\n",
        "        layer1 = self.dropout(F.relu(self.layer1(flattened)))\n",
        "        layer2 = self.dropout(F.relu(self.layer2(layer1)))\n",
        "        output = self.layer3(layer2)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12hcxYeCJrgu"
      },
      "source": [
        "### Build a new model with Dropouts\n",
        "- In addition to normalisation and weight decay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8tbnTAGGNn0"
      },
      "source": [
        "model = MNIST_Dropout()\n",
        "train_model(model, train_set, val_set, weight_decay=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8wNyYaaDy-4"
      },
      "source": [
        "# Answer the following questions\n",
        "# Q7. What is the best validation accuracy and when was it achieved?\n",
        "\n",
        "# Q8. Is the validation accuracy a bit better with dropouts, normalisation and weight decay?\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVrxJm5xJxGq"
      },
      "source": [
        "## Add Batch Norm\n",
        "- Add batch norm BEFORE activation and dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRn7xJh_S_4P"
      },
      "source": [
        "class MNIST_Dropout_BN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(28 * 28, 50)\n",
        "        self.bn1 = nn.BatchNorm1d(num_features=50)\n",
        "        self.layer2 = nn.Linear(50, 20)\n",
        "        # Q9. Add a suitable batch norm layer here\n",
        "        self.layer3 = nn.Linear(20, 10)\n",
        "        self.dropout = nn.Dropout(0.4) # drop out layer with 40% dropped out neuron\n",
        "    def forward(self, img):\n",
        "        flattened = img.view(-1, 28 * 28)\n",
        "        # Q10. Add batch norm to layer1 and layer2\n",
        "        out1 = self.dropout(F.relu(self.layer1(flattened))))\n",
        "        out2 = self.dropout(F.relu(self.layer2(out1))))\n",
        "        output = self.layer3(out2)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-kPmwUXklQe"
      },
      "source": [
        "model = MNIST_Dropout_BN()\n",
        "train_model(model, train_set, val_set, weight_decay=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0VV8i2iiz6g"
      },
      "source": [
        "### EXERCISE: Use Convolutions with Batch Norms\n",
        "- Use the **same training and validation data** set loading as before, i.e. you do not have to load the data again\n",
        "- Remember that BatchNorm1d accepts 2D or 3D inputs while BatchNorm2d only accepts 4D inputs\n",
        "- Use BatchNorm2d with Conv2d layers\n",
        "- Use Dropouts as well to get a model with better validation accuracy\n",
        "- Plot the graph of your final training loss, training and validation accuracies (you may want to call `train_model()`)\n",
        "- Extra: play around with the hyper parameters such as weight decay, learning, rate, etc. to help improve the model's performance\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5knUAX4nXx3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}